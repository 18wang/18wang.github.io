{"meta":{"title":"18wang","subtitle":"","description":"","author":"Wang Xy","url":"https://github.com/18wang","root":"/"},"pages":[],"posts":[{"title":"Python模拟点云生成","slug":"Python模拟点云生成","date":"2020-08-24T09:46:52.830Z","updated":"2020-08-24T09:58:45.321Z","comments":true,"path":"2020/08/24/Python模拟点云生成/","link":"","permalink":"https://github.com/18wang/2020/08/24/Python%E6%A8%A1%E6%8B%9F%E7%82%B9%E4%BA%91%E7%94%9F%E6%88%90/","excerpt":"","text":"模拟点云生成 用python生成点云, 加入一点噪声, 包括平面, 直线和圆柱面的点云 比较容易, numpy 生成点, 列方程, 画图, 保存(点云的保存要注意一点技巧) 123456789101112131415161718192021222324252627282930313233343536373839# 线点云 \"\"\"画一个任意线段点云, 加噪 噪声在noise中可以调节 - 采样步距 - 点云参数 t 范围 - 直线方程 X = X0+kx*t, Y = Y0+ky*t, Z = Z0+kz*t - 噪声大小 或 噪声类型\"\"\"step = 0.1 # 步距tlim = [-4, 10] # 参数 t 范围X0, Y0, Z0 = 0, 0, 0 # 参数式方程系数kx, ky, kz = 1, 1, 1from matplotlib import pyplot as pltimport numpy as npfrom mpl_toolkits.mplot3d import Axes3Dt = np.arange(tlim[0], tlim[1], step) # 生成点云 t 坐标 列X = X0 + kx * tY = Y0 + ky * tZ = Z0 + kz * t noise = (np.random.rand(t.shape[0])-0.5) * 0.1 # 加噪 [-0.5, 0.5) 噪声Zn = Z + noise# 存储数据点PC = np.dstack((X, Y, Zn))PCs = PC.reshape((t.shape[0],-1))np.savetxt(\"E:/LinePC.txt\", PCs, delimiter=',', fmt=\"%f\") # 画图fig = plt.figure() ax = Axes3D(fig)ax.scatter(X, Y, Zn, c='r') # 绘制数据点ax.set_zlabel('Z') # 坐标轴ax.set_ylabel('Y')ax.set_xlabel('X')plt.show() 12345678910111213141516171819202122232425262728293031323334353637383940# 平面点云 \"\"\"画一个任意平面点云, 加噪 噪声在noise中可以调节 - X, Y步距 - 点云 X, Y 范围 - 平面方程 Z = f(X, Y) - 噪声大小 或 噪声类型\"\"\"step = 0.25 # 步距xlim = [-4, 10] # 坐标范围ylim = [-4, 10]from matplotlib import pyplot as pltimport numpy as npfrom mpl_toolkits.mplot3d import Axes3DX = np.arange(xlim[0], xlim[1], step) # 生成点云 x坐标 列Y = np.arange(ylim[0], ylim[1], step)X, Y = np.meshgrid(X, Y) # 生成网格Z = X+Y # np.zeros_like(X)x, y = Z.shape # 加噪 [-0.5, 0.5) 噪声noise = (np.random.rand(x, y)-0.5) * 0.1 Zn = Z + noise# 存储数据点PC = np.dstack((X, Y, Zn))PCs = PC.reshape((x*y,-1))np.savetxt(\"E:/PlanePC.txt\", PCs, delimiter=',', fmt=\"%f\")# 画图fig = plt.figure() ax = Axes3D(fig)# 具体函数方法可用 help(function) 查看，如：help(ax.plot_surface)ax.plot_surface(X, Y, Zn, rstride=1, cstride=1, cmap='rainbow')ax.set_zlabel('Z') # 坐标轴ax.set_ylabel('Y')ax.set_xlabel('X')plt.show() 123456789101112131415161718192021222324252627282930313233343536373839404142434445# 圆柱侧面点云 \"\"\"画一个椭圆柱侧面点云, 以 z轴 为轴心, 向正负方向延申加噪 噪声在noiseX, noiseY中可以调节 - xoy 截面的采样角度步距 0~2π, z 轴方向的采样步距 - 点云 z轴 范围 - 椭圆正截面长短轴 (x/a)^2 + (y/b)^2 = 1 - 噪声大小 或 噪声类型\"\"\"stepz = 0.2 # z轴方向步距 stepA = 0.1 # xoy平面角度步距zlim = [-4, 1] # z坐标范围a, b = 1, 1 # 长轴短轴from matplotlib import pyplot as pltimport numpy as npfrom mpl_toolkits.mplot3d import Axes3DX = a * np.cos(np.arange(0,2*np.pi,stepA)) # 生成坐标Y = b * np.sin(np.arange(0,2*np.pi,stepA))Z = np.arange(zlim[0], zlim[1], stepz)X, _ = np.meshgrid(X, Z) Y, Z = np.meshgrid(Y, Z) shape0, shape1 = X.shape[0], X.shape[1]noiseX = (np.random.rand(shape0, shape1)-0.5) * 0.05 # 加噪 [-0.25, 0.25) 噪声noiseY = (np.random.rand(shape0, shape1)-0.5) * 0.05 # X Y 均加噪Xn = X + noiseXYn = Y + noiseY# 存储数据点PC = np.dstack((Xn, Yn, Z))PCs = PC.reshape((shape0*shape1,-1))np.savetxt(\"E:/CylinderPC.txt\", PCs, delimiter=',', fmt=\"%f\")# 画图fig = plt.figure() ax = Axes3D(fig)# 具体函数方法可用 help(function) 查看，如：help(ax.plot_surface)ax.plot_surface(Xn, Yn, Z, rstride=1, cstride=1, cmap='rainbow')ax.set_zlabel('Z') # 坐标轴ax.set_ylabel('Y')ax.set_xlabel('X')plt.show() 注意到圆柱面有一个豁口, 因为最后一个点和起始点没有首尾相连, 但用于Polyworks并无进一步处理的需要, 示意即可 保存的点云数据如下图所示","categories":[],"tags":[]},{"title":"kalman_filter","slug":"kalman_filter","date":"2020-08-19T08:47:14.117Z","updated":"2020-09-12T11:21:02.775Z","comments":true,"path":"2020/08/19/kalman_filter/","link":"","permalink":"https://github.com/18wang/2020/08/19/kalman_filter/","excerpt":"","text":"卡尔曼滤波 应用 激光雷达测距的数值经常发生跳变, 显示在软件里的值波动有点大. 用 matlab 对其进行滤波, 实现更好的显示效果, 提高测量精度. 前情提要 激光雷达的采样率是 1kHz, 1s 采 1000 个数据点 目前的方法是, 对每1000个点排序, 去掉最大最小各100个点, 取均值, 效果不够好 拟采用一种滤波的方法, 或者其他任何简单方便的算法, 得到稳定的测距值 当前只要处理实测距离不变, 测量值的跳变的问题; 若遇实际距离变化, 可能需要其他算法 数据文件 存储读数的csv文件结构如 图1 所示 卡尔曼滤波器 实用参考: 卡尔曼滤波 https://zhuanlan.zhihu.com/p/39912633 Matlab实现 https://blog.csdn.net/zengxiantao1994/article/details/71170728 这里面就不再赘述了, 知识点忘记了就回顾一下 总之, 卡尔曼滤波在输出预测, 信号滤波方面有着广泛的应用, 而且简单性能不错. 还可以深入学习的地方就是, 对参数的物理意义进一步深入理解, 便于调解应用 程序实现 Matlab 实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283%% 卡尔曼滤波% 实用参考: 卡尔曼滤波 https://zhuanlan.zhihu.com/p/39912633% Matlab实现 https://blog.csdn.net/zengxiantao1994/article/details/71170728filename = [\"2020-4-18-1320.csv\", \"2020-4-18-1324.csv\" , \"2020-4-18-1339.csv\"]; address = 'E:\\Temp\\testdata\\'; % 地址pL = 1000; % 1khz采样 sz = [2, 1]; % 保存 k-1估计值 和 k时刻估计值 即可Q = 1e-10; % 过程方差，反映连续两个采样点值的方差 Q↑ 稳定性↓ 示数变化速率↑R = 1e0; % 测量方差，反映激光器的测量精度 R↑ 稳定性↑ 示数变化速率↓ % 卡尔曼滤波器 我这里写的是针对线性系统的, 所以对于距离变化这种非线性的情况比较糟糕, 要么反应慢, 要么效果差% 我们可以设定一个阈值判断, 譬如说前后两秒的均值差距超过 T , 停用滤波, 差距小于 T (距离不变) 启用卡尔曼滤波for i = 1 % length(filename) % 文件名循环 data = csvread(strcat(address, filename(i))); [row, col] = size(data); % 每个csv行列大小 mean1s = zeros([fix(row/pL), 1]); % 均值 每 1s 数据 mean1skal = zeros([fix(row/pL), 1]); % kalman滤波后均值 %% kalman数据初始化 dhat = zeros(sz); % 对距离的后验估计, 即在k时刻，结合当前采样值与k-1时刻先验估计，得到结果 dhatresult = zeros([pL,1]); % 存储 dhat 结果 P = zeros(sz); % 后验估计方差 dhatminus = zeros(sz); % 先验估计值 Pminus = zeros(sz); % 先验估计方差 K = zeros(sz); % 卡尔曼增益 dhat(1) = data(1,1)+0.; % 最初的估计, 这里用均值 P(1) = 0.1; % 方差初值 for j = 1 : fix(row/pL) % 1s 数据点获取 d1000 = data((j-1)*pL+1:j*pL, 1); avg = mean(d1000); % 均值 mean1s(j) = avg; %% 卡尔曼滤波 for k = 2 : pL dhatminus(2) = dhat(1); % 时间更新, 沿用之前的估计值 Pminus(2) = P(1) + Q; % 预测方差=前时刻方差+过程方差 K(2) = Pminus(2) / (Pminus(2) + R); % 计算卡尔曼增益 dhat(2) = dhatminus(2) + K(2) * (d1000(k) - dhatminus(2)); % 校正后最优估计结果 P(2) = (1 - K(2)) * Pminus(2); % 计算最优估计方差 if k == 2 dhatresult(k-1) = dhat(k-1); % 存储 dhat(1) end dhatresult(k) = dhat(2); P(1) = P(2); % 更新后验估计方差 dhat(1) = dhat(2); % 更新下 1s 最初的估计, 这里用上一秒最后一个采样点 end mean1skal(j) = mean(dhatresult(1:end)); % 取 某 点以后的 % %% 画图 滤波前后 对比结果 % figure(1); % plot((j-1)*pL+1:j*pL, dhat); % hold on; % % plot([lmax+(j-1)*pL, lmin+(j-1)*pL], [dmax,dmin], 'ro'); % % hold on; % plot((j-1)*pL+1:j*pL, d1000); % hold on; % plot([(j-1)*pL+1, j*pL], [avg, avg], 'g'); % % legend(&#123;'datacurve',strcat('extreme point \\delta:', num2str(delta), ' avg:', num2str(avg)) &#125;, 'Location', 'best'); % hold off; % % 保存图片 % saveas(1, strcat(address, 'figure\\kalman', filename(i), '-',num2str(j), '.jpg')); % close; end figure(i); plot(mean1skal(1:end), '-o'); hold on; title('kalman vs ordinary data mean'); xlabel('s'); ylabel('value'); plot(mean1s(1:end), '--^'); hold off; end 结果展示 取了前10s的信号, 红色是原始信号, 绿色是原始信号均值, 蓝色是滤波后信号, 效果很不错. 把每秒的1000个信号取均值, 画出来的结果, 也显示, 平稳了很多. 程序和数据文件被放在了这里 还有媛姐改成的C#文件","categories":[],"tags":[]},{"title":"深度学习入门：基于Python的理论与实现-斋藤康毅","slug":"深度学习入门：基于Python的理论与实现-斋藤康毅","date":"2020-08-16T10:32:37.149Z","updated":"2020-08-16T10:47:01.318Z","comments":true,"path":"2020/08/16/深度学习入门：基于Python的理论与实现-斋藤康毅/","link":"","permalink":"https://github.com/18wang/2020/08/16/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%9A%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E7%8E%B0-%E6%96%8B%E8%97%A4%E5%BA%B7%E6%AF%85/","excerpt":"","text":"深度学习入门：基于Python的理论与实现 一本蛮简单的深度学习入门, 希望自己快快地过一遍! 随便记一些东西, 但愿可以. 资料: https://github.com/MemorialCheng/deep-learning-from-scratch 中文版 https://github.com/oreilly-japan/deep-learning-from-scratch 日文原版 12345678import numpy as np a = np.array([[2,3,4],[1,2,3]])b = np.array([3,2,1])print(a.shape, b.shape)print(np.dot(a, b)) # 点积 (2, 3) (3,) [16 10] 第三章 神经网络 神经网络的任一权重: $$\\displaystyle W^{( 1)}_{12}$$ 上标表明作用在第几层, 下标表示连接前层中的2到当前层中的1. 总体上可以写作: $$ A^{(1)} = XW^{(1)} + B^{(1)}$$ B为偏置, X为前层输入, A为该层结果, W为权重 实现一个3层神经网络 1234567891011X = np.array([1.0, 0.5])W1 = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])B1 = np.array([0.1, 0.2, 0.3])print(W1.shape) # (2, 3)print(X.shape) # (2,)print(B1.shape) # (3,)A1 = np.dot(X, W1) + B1print(A1) (2, 3) (2,) (3,) [0.3 0.7 1.1] 123456def sigmoid(a): return 1/(1+np.exp(-1*a))Z1 = sigmoid(A1) # Z1 第一层激活函数作用后的结果print(A1) # [0.3, 0.7, 1.1]print(Z1) # [0.57444252, 0.66818777, 0.75026011] [0.3 0.7 1.1] [0.57444252 0.66818777 0.75026011] 123456W2 = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])B2 = np.array([0.1, 0.2])A2 = np.dot(Z1, W2) + B2Z2 = sigmoid(A2)print(Z2) # 从第一层到第二层 [0.62624937 0.7710107 ] 12345678def identity_function(x): return xW3 = np.array([[0.1, 0.3], [0.2, 0.4]])B3 = np.array([0.1, 0.2])A3 = np.dot(Z2, W3) + B3Y = identity_function(A3) # 这里我们的输出层的激活函数是一个恒等函数# 或者Y = A3print(Y) [0.31682708 0.69627909] 输出层的激活函数选取问题: 回归问题可以使用恒等函数，二元分类问题可以使用 sigmoid 函数，多元分类问题可以使用 softmax 函数 softmax 函数表达式: $$y_k = \\frac{exp(a_k)}{\\sum_{i=1}^{n}exp(a_i)}$$ 12345678910def softmax(a): c = np.max(a) exp_a = np.exp(a - c) # 溢出对策, a太大很容易溢出 return exp_a/sum(exp_a)a = np.array([0.3, 2.9, 4.0])y = softmax(a)print(y)print(sum(y)) # 和永远是1, 可以认为 Yk 是一个输出概率 [0.01821127 0.24519181 0.73659691] 1.0 MNIST 手写字 经典的手写字识别例子, 可能是不允许爬虫了, 只能手动下载文件到对应目录, 但是问题不大. 让我们照着它的代码开始吧! 我们做了一个数据的加载工作, load_mnist: flatten 展开数据 normalize 归一化每个像素 使用 pickle 保存实时的运行对象, 简化运算过程. 方便存取网络的权重 123456789101112# 导入数据import sys, osos.chdir(\"E:/Temp/deep-learning-from-scratch-master/ch03\")sys.path.append(os.pardir) # pardir 当前目录的父目录from dataset.mnist import load_mnist# 第⼀次调⽤会花费⼏分钟……(x_train, t_train), (x_test, t_test) =load_mnist(flatten=True,normalize=False)# 输出各个数据的形状print(x_train.shape) # (60000, 784)print(t_train.shape) # (60000,)print(x_test.shape) # (10000, 784)print(t_test.shape) # (10000,) (60000, 784) (60000,) (10000, 784) (10000,) 1234567891011121314151617181920# 显示MNIST图像import sys, ossys.path.append(os.pardir)import numpy as npfrom dataset.mnist import load_mnistfrom PIL import Image # 熟悉的PIL模块def img_show(img): pil_img = Image.fromarray(np.uint8(img)) pil_img.show()(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False)img = x_train[0]label = t_train[0]print(label) # 5print(img.shape) # (784,) 已经 flatten 过了img = img.reshape(28, 28) # 把图像的形状变成原来的尺⼨print(img.shape) # (28, 28)img_show(img) 5 (784,) (28, 28) 12345678910111213141516171819202122232425262728293031323334# 构建神经网络import pickledef get_data(): \"\"\" 获取数据 \"\"\" (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, flatten=True, one_hot_label=False) return x_test, t_testdef init_network(): \"\"\" 初始化神经网络 已经学习好的权重数据在sample_weight.pkl中 \"\"\" with open(\"sample_weight.pkl\", 'rb') as f: network = pickle.load(f) return networkdef predict(network, x): \"\"\" 三层神经网络 输出采用softmax函数 \"\"\" W1, W2, W3 = network['W1'], network['W2'], network['W3'] b1, b2, b3 = network['b1'], network['b2'], network['b3'] a1 = np.dot(x, W1) + b1 z1 = sigmoid(a1) a2 = np.dot(z1, W2) + b2 z2 = sigmoid(a2) a3 = np.dot(z2, W3) + b3 y = softmax(a3) return y 1234567891011121314# 开始学习x, t = get_data()network = init_network()accuracy_cnt = 0for i in range(len(x)): y = predict(network, x[i]) # np.argmax(x) 将获取被赋给参数 x 的数组中的最大值元素的索引 p = np.argmax(y) # 获取概率最⾼的元素的索引 if p == t[i]: accuracy_cnt += 1print(\"Accuracy:\" + str(float(accuracy_cnt) / len(x))) Accuracy:0.9352 1234567891011121314# 批处理 提高运算速度x, t = get_data()network = init_network()batch_size = 100# 批数量accuracy_cnt = 0for i in range(0, len(x), batch_size): x_batch = x[i:i+batch_size] y_batch = predict(network, x_batch) p = np.argmax(y_batch, axis=1) accuracy_cnt += np.sum(p == t[i:i+batch_size]) 第四章 神经网络的学习 最终目的, 提高泛化能力 损失函数: 对于单个样本 均方误差 $ E=\\frac{1}{2}\\sum_{k}(y_k-t_k)^2$ 交叉熵误差 $ E=-\\sum_{k}t_k log(y_k) $ 实际的学习中, 常用小批量(mini batch)学习, 将样本顺序打乱, 固定个数的样本为一组, 提高效率, 防止过拟合. 12345678# 交叉熵误差def cross_entropy_error(y, t): if y.ndim == 1: t = t.reshape(1, t.size) y = y.reshape(1, y.size) batch_size = y.shape[0] return -np.sum(t * np.log(y + 1e-7)) / batch_size 12345678910111213141516171819202122232425262728293031import numpy as npdef numerical_gradient(f, x): \"\"\" f(x) 在 x 处的 数值 梯度 f 为函数对象 x 为偏导所在位置, 可以是数组 \"\"\" h = 1e-4 # 0.0001 grad = np.zeros_like(x) # ⽣成和x形状相同的数组 for idx in range(x.size): tmp_val = x[idx] # f(x+h)的计算 x[idx] = tmp_val + h fxh1 = f(x) # f(x-h)的计算 x[idx] = tmp_val - h fxh2 = f(x) grad[idx] = (fxh1 - fxh2) / (2*h) x[idx] = tmp_val # 还原值 return graddef function_2(x): return x[0]**2 + x[1]**2# 或者return np.sum(x**2)# 都是 int 就悲剧了, float 没事, 可能是数值精度问题.print(numerical_gradient(function_2, np.array([3.0, 4.0]))) [6. 8.] 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980# 两层神经网络# coding: utf-8 import sys, osos.chdir(\"E:/Temp/deep-learning-from-scratch-master/ch04\")sys.path.append(os.pardir) # 为了导入父目录的文件而进行的设定from common.functions import *from common.gradient import numerical_gradientclass TwoLayerNet: def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01): # 初始化权重 self.params = &#123;&#125; self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size) self.params['b1'] = np.zeros(hidden_size) self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size) self.params['b2'] = np.zeros(output_size) def predict(self, x): W1, W2 = self.params['W1'], self.params['W2'] b1, b2 = self.params['b1'], self.params['b2'] a1 = np.dot(x, W1) + b1 z1 = sigmoid(a1) a2 = np.dot(z1, W2) + b2 y = softmax(a2) return y # x:输入数据, t:监督数据 def loss(self, x, t): y = self.predict(x) return cross_entropy_error(y, t) def accuracy(self, x, t): y = self.predict(x) y = np.argmax(y, axis=1) t = np.argmax(t, axis=1) accuracy = np.sum(y == t) / float(x.shape[0]) return accuracy # x:输入数据, t:监督数据 def numerical_gradient(self, x, t): loss_W = lambda W: self.loss(x, t) grads = &#123;&#125; grads['W1'] = numerical_gradient(loss_W, self.params['W1']) grads['b1'] = numerical_gradient(loss_W, self.params['b1']) grads['W2'] = numerical_gradient(loss_W, self.params['W2']) grads['b2'] = numerical_gradient(loss_W, self.params['b2']) return grads def gradient(self, x, t): W1, W2 = self.params['W1'], self.params['W2'] b1, b2 = self.params['b1'], self.params['b2'] grads = &#123;&#125; batch_num = x.shape[0] # forward a1 = np.dot(x, W1) + b1 z1 = sigmoid(a1) a2 = np.dot(z1, W2) + b2 y = softmax(a2) # backward dy = (y - t) / batch_num grads['W2'] = np.dot(z1.T, dy) grads['b2'] = np.sum(dy, axis=0) da1 = np.dot(dy, W2.T) dz1 = sigmoid_grad(a1) * da1 grads['W1'] = np.dot(x.T, dz1) grads['b1'] = np.sum(dz1, axis=0) return grads 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859# 使用 两层神经网络 进行mini-batch训练# coding: utf-8import sys, ossys.path.append(os.pardir) # 为了导入父目录的文件而进行的设定import numpy as npimport matplotlib.pyplot as pltfrom dataset.mnist import load_mnistfrom two_layer_net import TwoLayerNet# 读入数据(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)iters_num = 10000 # 适当设定循环的次数train_size = x_train.shape[0]batch_size = 100learning_rate = 0.1train_loss_list = []train_acc_list = []test_acc_list = []iter_per_epoch = max(train_size / batch_size, 1)for i in range(iters_num): batch_mask = np.random.choice(train_size, batch_size) x_batch = x_train[batch_mask] t_batch = t_train[batch_mask] # 计算梯度 #grad = network.numerical_gradient(x_batch, t_batch) grad = network.gradient(x_batch, t_batch) # 更新参数 for key in ('W1', 'b1', 'W2', 'b2'): network.params[key] -= learning_rate * grad[key] loss = network.loss(x_batch, t_batch) train_loss_list.append(loss) # 每个 mini batch 之后判断准确率 if i % iter_per_epoch == 0: train_acc = network.accuracy(x_train, t_train) test_acc = network.accuracy(x_test, t_test) train_acc_list.append(train_acc) test_acc_list.append(test_acc) print(\"train acc, test acc | \" + str(train_acc) + \", \" + str(test_acc))# 绘制图形markers = &#123;'train': 'o', 'test': 's'&#125;x = np.arange(len(train_acc_list))plt.plot(x, train_acc_list, label='train acc')plt.plot(x, test_acc_list, label='test acc', linestyle='--')plt.xlabel(\"epochs\")plt.ylabel(\"accuracy\")plt.ylim(0, 1.0)plt.legend(loc='lower right')plt.show() train acc, test acc | 0.10218333333333333, 0.101 train acc, test acc | 0.7860666666666667, 0.7923 train acc, test acc | 0.8741666666666666, 0.8779 train acc, test acc | 0.8971333333333333, 0.9007 train acc, test acc | 0.9080833333333334, 0.9108 train acc, test acc | 0.91445, 0.9182 train acc, test acc | 0.9196833333333333, 0.9227 train acc, test acc | 0.9234166666666667, 0.9271 train acc, test acc | 0.9276, 0.9308 train acc, test acc | 0.9304166666666667, 0.9339 train acc, test acc | 0.9337166666666666, 0.935 train acc, test acc | 0.9369666666666666, 0.937 train acc, test acc | 0.9384833333333333, 0.9397 train acc, test acc | 0.9418, 0.9421 train acc, test acc | 0.9435333333333333, 0.9436 train acc, test acc | 0.9456, 0.9459 train acc, test acc | 0.9472833333333334, 0.9471 第五章 误差反向传播法 使用计算图的知识, 利用图的求导(backward)方便的特点; 图也可以存储计算过程中的一些数据(class) 每个节点都有 正向传输(forward) 和 反向传输(backward) 12345678910111213141516171819# 乘法层class MulLayer: def __init__(self): self.x = None self.y = None def forward(self, x, y): self.x = x self.y = y out = x * y return out def backward(self, dout): dx = dout * self.y # 翻转x和y dy = dout * self.x # 导数是 对方乘数 return dx, dy 12345678910111213141516# 加法层class AddLayer: def __init__(self): pass def forward(self, x, y): out = x + y return out def backward(self, dout): dx = dout * 1 # 导数是 1 dy = dout * 1 return dx, dy 我们将 Y = X * W + B 称作仿射变换, 对应步骤称为仿射变换层.(Affine) 仿射层中参与运算的都是矩阵 误差反向传播法求梯度 比数值法效率更高. 但我们常用 数值法 计算梯度, 对结果进行比较. 从而实现梯度确认. 1234567891011121314151617181920212223# 计算 数值微分求出的梯度和误差反向传播法求出的梯度的误差# coding: utf-8import sys, osos.chdir(\"E:\\\\Temp\\\\deep-learning-from-scratch-master\\\\ch05\")sys.path.append(os.pardir) # 为了导入父目录的文件而进行的设定import numpy as npfrom dataset.mnist import load_mnistfrom two_layer_net import TwoLayerNet# 读入数据(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)x_batch = x_train[:3]t_batch = t_train[:3]grad_numerical = network.numerical_gradient(x_batch, t_batch)grad_backprop = network.gradient(x_batch, t_batch)for key in grad_numerical.keys(): diff = np.average( np.abs(grad_backprop[key] - grad_numerical[key]) ) print(key + \":\" + str(diff)) W1:4.5174184319697615e-10 b1:2.397918682756723e-09 W2:4.725159762929652e-09 b2:1.398749418138334e-07 第五章所学 通过使用计算图，可以直观地把握计算过程。 计算图的节点是由局部计算构成的。局部计算构成全局计算。 计算图的正向传播进行一般的计算。通过计算图的反向传播，可以计算各个节点的导数。 通过将神经网络的组成元素实现为层，可以高效地计算梯度（反向传播法）。 通过比较数值微分和误差反向传播法的结果，可以确认误差反向传播法的实现是否正确（梯度确认）。 第6章 本章所学的内容 参数的更新方法，除了 SGD 之外，还有Momentum、AdaGrad、Adam等方法。 权重初始值的赋值方法对进行正确的学习非常重要。 作为权重初始值，Xavier 初始值、He初始值等比较有效。 -通过使用 Batch Normalization，可以加速学习，并且对初始值变得健壮。 抑制过拟合的正则化技术有权值衰减、Dropout等。 逐渐缩小“好值”存在的范围是搜索超参数的一个有效方法。 第7章 本章所学的内容 CNN在此前的全连接层的网络中新增了卷积层和池化层。 使用im2col 函数可以简单、高效地实现卷积层和池化层。 通过CNN的可视化，可知随着层次变深，提取的信息愈加高级。 LeNet和AlexNet是CNN的代表性网络。 在深度学习的发展中，大数据和GPU做出了很大的贡献。 第8章 本章所学的内容 对于大多数的问题，都可以期待通过加深网络来提高性能。 在最近的图像识别大赛ILSVRC中，基于深度学习的方法独占鳌头，使用的网络也在深化。 VGG、GoogLeNet、ResNet等是几个著名的网络。 基于GPU、分布式学习、位数精度的缩减，可以实现深度学习的高速化。 深度学习（神经网络）不仅可以用于物体识别，还可以用于物体检测、图像分割。 深度学习的应用包括图像标题的生成、图像的生成、强化学习等。最近，深度学习在自动驾驶上的应用也备受期待。 我都学完了, 后面的草率一点, 2016年的书, 很棒的入门","categories":[],"tags":[]},{"title":"pdf添加页码","slug":"pdf添加页码","date":"2020-06-21T02:11:38.051Z","updated":"2020-06-21T02:35:43.175Z","comments":true,"path":"2020/06/21/pdf添加页码/","link":"","permalink":"https://github.com/18wang/2020/06/21/pdf%E6%B7%BB%E5%8A%A0%E9%A1%B5%E7%A0%81/","excerpt":"","text":"给PDF文件添加页码 有些扫描的, 或者本身没有添加页码的pdf文件, 很长, 也没有书签目录可以跳转, 尽管很多pdf编辑器可以手动添加目录, 但仍然不符合效率的原则. 当然, 我们可以写程序实现, 在需要编辑的pdf样本比较少的情况下, 小工具也可以很有用. 这篇博客给我提供了很大的帮助. 下载&quot;老马&quot;自己写的PdgCntEditor 博客地址: https://www.cnblogs.com/stronghorse/ 最新软件下载地址： 链接：https://pan.baidu.com/s/1BC0JTOACnfePv8LokD5GCg 提取码：tyor English version: http://www.mediafire.com/folder/f0z2hexqdnr9a/Software 从京东, 亚马逊, 图书内容等等渠道, 获得文件目录. 最好复制到excel里面, 分两栏, 序号标题一栏, 页码一栏(两栏之间天然用制表符Tab分开) 运行PdgCntEditor.exe, 打开 ***.pdf, 将目录粘贴到空白处, 选中目录. 自动缩进 设定基准页, 即目录中P1对应的实际PDF页数. 保存文件","categories":[],"tags":[]},{"title":"蒲宇琦考研成绩排名估算","slug":"蒲宇琦考研成绩排名估算","date":"2020-05-10T07:19:50.010Z","updated":"2020-05-10T07:37:36.617Z","comments":true,"path":"2020/05/10/蒲宇琦考研成绩排名估算/","link":"","permalink":"https://github.com/18wang/2020/05/10/%E8%92%B2%E5%AE%87%E7%90%A6%E8%80%83%E7%A0%94%E6%88%90%E7%BB%A9%E6%8E%92%E5%90%8D%E4%BC%B0%E7%AE%97/","excerpt":"","text":"研究蒲宇琦成绩排名_结合研究生考试的成绩分布情况 尝试应用一两个具体的例子 中南财经政法大学的例子表明, 样本太少异常难受 江苏2018年高考的例子表明, 十分接近正态分布(因为缺乏完整数据, 难以直接估算) 调整蒲宇琦西南交大的数据, 还是较为准确地刻画了整个考生的成绩分布. 结果: 分数线 349.6126342475794 均分 317.4427612973726 他的成绩 356.62492204051085 成绩排名 130.84695647606708 123456789import numpy as npimport matplotlib.pyplot as pltsample = np.random.normal(loc=10 ,size=1000) plt.hist(sample) # 用正态分布练一下 PDF 图像plt.show() 12345678910import numpy as npimport matplotlib.pyplot as pltsample = np.random.normal(loc=10 ,size=1000)hist, bin_edges = np.histogram(sample) # CDF 画法cdf = np.cumsum(hist)plt.plot(cdf)plt.show() 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849\"\"\"网上找了一个例子, 太难了, 样本数量过小\"\"\"import numpy as npimport matplotlib.pyplot as plt# 中南财经政法大学 统计与数学学院2020年硕士研究生入学考试初试成绩分数段公告# http://tsxy.zuel.edu.cn/2020/0417/c4801a240926/page.htmrawZN = \"\"\"['400分以上,395分以上 390分以上 385分以上 380分以上 375分以上 370分以上 365分以上 360分以上 355分以上 350分以上 345分以上'][[2 4 5 10 15 15 17 19 21 26 29 332 4 6 6 8 12 14 19 23 29 39 4628 38 55 73 103 135 167 209 243 275 311 344]]\"\"\"# 格式上进行一些处理rawZN = rawZN.replace(\"\\t\", \",\") titleZN, dataZN = rawZN.split(\"\\n\",maxsplit=1)titleZN = titleZN.replace(\",\", \"\\',\\'\")dataZN = dataZN.replace(\"\\n\", \"],[\")titleZN = eval(titleZN)dataZN = eval(dataZN)dataZN = np.array(dataZN)print(dataZN)pureZN = []for i in dataZN: i[1:] -= i[:-1].copy() pureZN.append(i)pureZN = np.array(pureZN)print(pureZN)t = 1for i in pureZN: plt.subplot(eval('31'+str(t))) t += 1 # hist, bin_edges = np.histogram(i) plt.plot(i) plt.xticks(range(len(titleZN))[::3], titleZN[::3]) ## 可以设置坐标字# hist, bin_edges = np.histogram(sample)# cdf = np.cumsum(hist)# plt.plot(cdf)plt.rcParams['font.sans-serif']=['SimHei'] #用来正常显示中文标签plt.rcParams['axes.unicode_minus']=False #用来正常显示负号plt.show() [[ 2 4 5 10 15 15 17 19 21 26 29 33] [ 2 4 6 6 8 12 14 19 23 29 39 46] [ 28 38 55 73 103 135 167 209 243 275 311 344]] [[ 2 2 1 5 5 0 2 2 2 5 3 4] [ 2 2 2 0 2 4 2 5 4 6 10 7] [28 10 17 18 30 32 32 42 34 32 36 33]] 12345678910111213141516171819202122232425262728293031323334353637383940414243444546import numpy as npimport matplotlib.pyplot as plt# 江苏：2018年普通高考文理科逐分段统计表 理科部分# https://gaokao.chsi.com.cn/gkxx/zc/ss/201806/20180624/1699971659.htmlrawJS = \"\"\"[106,129,153,176,206,244,294,349,403,481,554,632,729,824,941,1073,1212,1374,1532,1701,1905,2155,2410,2673,2977,3300,3640,4011,4417,4851,5337,5826,6386,6970,7558,8196,8894,9624,10397,11188,12010,12927,13878,14865,15908,16949,18069,19224,20426,21662,22956,24259,25683,27082,28578,30126,31696,33251,34844,36532,38197,39968,41732,43537,45377,47223,49066,50899,52843,54809,56818,58853,60827,62874,64881,66887,68883,70894,72878,74876,76939,78846,80785,82746,84717,86691,88640,90569,92470,94303,96130,97984,99833,101621,103400,105171,106842,108538,110109,111659,113259,114858,116332,117807,119232,120592,121985,123348,124643,125898,127159,128392,129577,130768,131884,133003,134133,135180,136221,137206,138195,139160,140082,141006,141853,142718,143558,144384,145131,145856,146562,147204,147854,148486,149146,149786,150353]\"\"\"titleJS = \"\"\"['411','410','409','408','407','406','405','404','403','402','401','400','399','398','397','396','395','394','393','392','391','390','389','388','387','386','385','384','383','382','381','380','379','378','377','376','375','374','373','372','371','370','369','368','367','366','365','364','363','362','361','360','359','358','357','356','355','354','353','352','351','350','349','348','347','346','345','344','343','342','341','340','339','338','337','336','335','334','333','332','331','330','329','328','327','326','325','324','323','322','321','320','319','318','317','316','315','314','313','312','311','310','309','308','307','306','305','304','303','302','301','300','299','298','297','296','295','294','293','292','291','290','289','288','287','286','285','284','283','282','281','280','279','278','277','276','275']\"\"\"rawJS = np.array(eval(rawJS))titleJS = eval(titleJS)titleJS = [int(i) for i in titleJS]total = rawJS[-1] # 总人数rawJS[1:] -= rawJS[:-1].copy()plt.figure(1)plt.plot(rawJS/total) # 画PDFplt.xticks(range(len(titleJS))[::5], titleJS[::5]) ## 可以设置坐标字plt.rcParams['font.sans-serif']=['SimHei'] #用来正常显示中文标签plt.rcParams['axes.unicode_minus']=False #用来正常显示负号# plt.show()sample = np.random.choice(titleJS, p=rawJS/total,size=10000)meanJS = sample.mean() # 正态分布拟合delta = sample.std()import scipy.statsp = scipy.stats.norm.pdf(titleJS, meanJS, delta) # 返回N(mu,sigma^2)的概率密度函数在 x 处的值plt.plot(p)plt.figure(2)cdfJS = rawJS.cumsum() # 画CDFplt.xticks(range(len(titleJS))[::5], titleJS[::5]) ## 可以设置坐标字plt.plot(cdfJS/total)# plt.show()titleJS.sort()c = scipy.stats.norm.cdf(titleJS, meanJS, delta)plt.plot(c)plt.show() 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768import numpy as npimport matplotlib.pyplot as pltimport scipy.statsnum = 1560stopR = 204stopPointR = 349 puR = 356mean = 318std = 28sampleRan = np.random.normal(mean, std, 155400)sample = np.sort(sampleRan) # 计算分数线stop = np.percentile(sample, 100-100*stopR/num) # percentile 返回百分位数对应的值print('估计分数线', stop)# 换算成蒲宇琦的分数meanR = stopPointR/stop*meanprint(\"实际均分\",meanR) # 实际 平均分pu = puR*mean/meanRprint(pu)rank = scipy.stats.norm.cdf(pu, mean, std)print((1-rank)*num)plt.rcParams['font.sans-serif']=['SimHei'] #用来正常显示中文标签plt.rcParams['axes.unicode_minus']=False #用来正常显示负号L = np.linspace(200, 430, num=500)Lpdf = scipy.stats.norm.pdf(L, meanR, std)plt.subplot(211)plt.plot(L,Lpdf)plt.title(\"成绩分布概率密度\")plt.xlabel(\"成绩\") # x轴上的名字plt.ylabel(\"概率密度\") # y轴上的名字# 画分数线point1 = [stop,scipy.stats.norm.pdf(stop, meanR, std)]plt.plot([point1[0],point1[0]],[point1[1],0],'r--',linewidth = 2)plt.annotate('分数线', xy=point1)# 画蒲宇琦point1 = [puR,scipy.stats.norm.pdf(pu, meanR, std)]plt.plot([point1[0],point1[0]],[point1[1],0],'g--',linewidth = 1.5)plt.annotate('pyq', xy=point1)plt.xlim((L[0],L[-1]))plt.ylim((0,0.015))plt.xticks([int(i) for i in L[::20]], [int(i) for i in L[::20]]) ## 可以设置坐标字Lcdf = scipy.stats.norm.cdf(L, meanR, std)plt.subplot(212)plt.plot(L,Lcdf*num)plt.title(\"成绩排名(累计分布)\")plt.xticks([int(i) for i in L[::20]], [int(i) for i in L[::20]]) ## 可以设置坐标字plt.yticks(range(num,0,-1)[::100], [i for i in range(num)[::100]])plt.xlabel(\"成绩\") # x轴上的名字plt.ylabel(\"排名\") # y轴上的名字# 画分数线point1 = [stop,scipy.stats.norm.cdf(stop, meanR, std)*num]plt.plot([point1[0],point1[0],L[0]],[0,point1[1],point1[1]],'r--',linewidth = 2)plt.annotate('分数线', xy=[point1[0]-4, point1[1]-80])# 画蒲宇琦point1 = [puR,scipy.stats.norm.cdf(pu, meanR, std)*num]plt.plot([point1[0],point1[0],L[0]],[0,point1[1],point1[1]],'g--',linewidth = 1.5)plt.annotate('pyq', xy=[point1[0]+2, point1[1]-20])plt.xlim((L[0],L[-1]))plt.ylim((0,1.05*num))plt.show() 估计分数线 349.6126342475794 实际均分 317.4427612973726 356.62492204051085 130.84695647606708","categories":[],"tags":[]},{"title":"Hexo博客添加Latex公式","slug":"Hexo博客添加Latex公式","date":"2020-04-02T10:13:46.361Z","updated":"2020-04-02T10:18:33.886Z","comments":true,"path":"2020/04/02/Hexo博客添加Latex公式/","link":"","permalink":"https://github.com/18wang/2020/04/02/Hexo%E5%8D%9A%E5%AE%A2%E6%B7%BB%E5%8A%A0Latex%E5%85%AC%E5%BC%8F/","excerpt":"","text":"注意点: 链接对于使用https协议的静态网站来说，所使用的cdn地址需要显式地添加 https: //，修改config文件的cdn的地址之后，重新部署，发现一切正常 链接 下文在 hexo 中，你会发现我们不能用 Latex 语法来书写数学公式，这对于书写学术博客来说是很大的不便，因为我们会经常碰到很多的数学公式推导，但是我们可以通过安装第三方库来解决这一问题。第一步： 使用Kramed代替 Markedhexo 默认的渲染引擎是 marked，但是 marked 不支持 mathjax。 kramed 是在 marked 的基础上进行修改。我们在工程目录下执行以下命令来安装 kramed.npm uninstall hexo-renderer-marked --save npm install hexo-renderer-kramed --save 然后，更改&lt;your-project-dir&gt;/node_modules/hexo-renderer-kramed/lib/renderer.js，更改：// Change inline math rule function formatText(text) { // Fit kramed's rule: $$ + \\1 + $$ return text.replace(/`\\$(.*?)\\$`/g, '$$$$$1$$$$'); } 为：// Change inline math rule function formatText(text) { return text; } 第二步: 停止使用 hexo-math首先，如果你已经安装 hexo-math, 请卸载它：npm uninstall hexo-math --save 然后安装 hexo-renderer-mathjax 包：npm install hexo-renderer-mathjax --save 第三步: 更新 Mathjax 的 CDN 链接首先，打开&lt;path-to-your-project&gt;/node_modules/hexo-renderer-mathjax/mathjax.html然后，把&lt;script&gt;更改为：&lt;script&lt;/span&gt; src=","categories":[],"tags":[]},{"title":"SVG","slug":"SVG","date":"2020-04-01T16:00:00.000Z","updated":"2020-04-02T10:00:15.437Z","comments":true,"path":"2020/04/02/SVG/","link":"","permalink":"https://github.com/18wang/2020/04/02/SVG/","excerpt":"","text":"SVG 学习主要教程网站mozilla developer主要记录我的一些草稿和学习内容.SVG的主要参考文档 入门SVG是一种XML语言的，和XHTML很像，它可以用来绘制矢量图形，例如右面展示的图形。SVG可以通过定义必要的线和形状来创建一个图形，也可以修改已有的位图，或者将这两种方式结合起来创建图形。图形和其组成部分可以形变（be transformed）、合成、或者通过滤镜完全改变外观。 所有的现代浏览器都支持SVG, 但是各种SVG浏览器是有差异的, 可能会出现显示方面的问题. 最接近的“完整版”SVG版本是1.1版, SVG 2.0正在制定当中. 一个简单的例子下面是一段xml代码, 文件名是 **.svg , 但也可以使用 **.xml , 在浏览器中打开都会显示svg图片.在服务器支持gzip时, 也可以用 **.svgz 命名并压缩大型SVG文件123456789101112&lt;svg version=\"2\" baseProfile=\"full\" width=\"300\" height=\"200\" xmlns=\"http://www.w3.org/2000/svg\"&gt; &lt;rect width=\"100%\" height=\"100%\" fill=\"red\" /&gt; &lt;circle cx=\"150\" cy=\"100\" r=\"80\" fill=\"green\" /&gt; &lt;text x=\"150\" y=\"125\" font-size=\"60\" text-anchor=\"middle\" fill=\"white\"&gt;汉字&lt;/text&gt;&lt;/svg&gt; 服务器配置错误是svg文件出错的常见原因, 容易出现文本和乱码, 一定要努力保证在该环节没有问题. 坐标定位SVG采用常见的Canvas坐标定位, 从高到低从左到右, 单位距离为1px 定义一个100*100的矩形1234567&lt;svg version=\"2\" baseProfile=\"full\" xmlns=\"http://www.w3.org/2000/svg\"&gt; &lt;rect x=\"0\" y=\"0\" width=\"100\" height=\"100\" /&gt;&lt;/svg&gt;就会出现一个大黑块 像素大小通常 1px 便是用户屏幕的1个像素, 和CSS一样, SVG也能定义相对大小和绝对大小.在SVG根元素中, 可以如下定义1&lt;svg width=\"50\" height=\"50\" viewBox=\"0 0 100 100\" &gt;定义画布尺寸为50*50px, 显示的坐标范围100*100px, 实现了缩小一半的效果. 和Qt类似, 用户设备和单位像素的映射关系叫用户坐标系统, 缩放、旋转、倾斜、翻转等功能均可实现. 基本形状下面是一些常见的基本形状, 我们可以直接运用他们或者用他们构建出更复杂的形状. 分别是 矩形, 圆角矩形, 圆, 椭圆, 直线, 折线, 多边形, 曲线 矩形 圆角矩形12&lt;rect x=\"10\" y=\"10\" width=\"30\" height=\"30\" stroke=\"black\" fill=\"transparent\" stroke-width=\"5\"/&gt;&lt;rect x=\"60\" y=\"10\" rx=\"10\" ry=\"10\" width=\"30\" height=\"30\" stroke=\"black\" fill=\"transparent\" stroke-width=\"5\"/&gt; 参数: 左上角的x,y坐标 长度 宽度 rx ry圆角半径 圆 椭圆12&lt;circle cx=\"25\" cy=\"75\" r=\"20\" stroke=\"red\" fill=\"transparent\" stroke-width=\"5\"/&gt;&lt;ellipse cx=\"75\" cy=\"75\" rx=\"20\" ry=\"5\" stroke=\"red\" fill=\"transparent\" stroke-width=\"5\"/&gt; 参数: cx cy中心坐标 r半径 rx x方向半轴 ry y方向半轴 椭圆的参数还挺难受的, 不过中心点也还行 线 折线 多边形12345&lt;line x1=\"10\" x2=\"50\" y1=\"110\" y2=\"150\" stroke=\"orange\" fill=\"transparent\" stroke-width=\"5\"/&gt;&lt;polyline points=\"60 110 65 120 70 115 75 130 80 125 85 140 90 135 95 150 100 145\" stroke=\"orange\" fill=\"transparent\" stroke-width=\"5\"/&gt;&lt;polygon points=\"50 160 55 180 70 180 60 190 65 205 50 195 35 205 40 190 30 180 45 180\" stroke=\"green\" fill=\"transparent\" stroke-width=\"5\"/&gt; 参数: x y起点终点坐标 points点集 xi yi 多边形和折线不同的是, 多边形最终回到原点, 折线落在最后一点. 点集中每个数字用空白符、逗号、终止命令或者换行符分隔开, 每个点必须包含2个数字 路径1&lt;path d=\"M20,230 Q40,205 50,230 T90,230\" fill=\"none\" stroke=\"blue\" stroke-width=\"5\"/&gt; 参数: d一个点集数列路径几乎是万能的, 也是最常见的, 可以用来绘制一切线条. 路径作图详解path元素的形状是通过属性d定义的，属性d的值是一个“命令+参数”的序列. 缩写 意义 备注 当前点坐标($x_0$,$y_0$) M x y 画笔移动到点($x,y$) 移动不产生笔迹 L x y 画($x_0$,$y_0$)到点($x$,$y$)的线段 H x 画($x_0$,$y_0$)到点(x,$y_0$)的水平线 V y 画($x_0$,$y_0$)到点($x_0$,$y$)的垂直线 Z/z 画($x_0$,$y_0$)到路径起点 无参数,不区分大小写 C $x_1$ $y_1$, $x_2$ $y_2$, $x$ $y$ 三次贝塞尔曲线 对应点 $P_0 $ $x_0,y_0$ / $P_1 $ $x_1,y_1$ / $P_2$ $x_2,y_2$ / $P_3$ $x,y$ S $x_2$ $y_2$, $x$ $y$ 简化的多个三次贝塞尔曲线 每个曲线的$P_1$控制点和前一曲线$P_2$对称, 可省(蓝点) Q $x_1$ $y_1$, $x$ $y$ 二次贝塞尔曲线 类似三次… T $x$ $y$ 简化的多个二次贝塞尔曲线 A $rx ry x-axis-rotation$ $large-arc-flag sweep-flag x y$ 弧形命令 $rx$ x方向半轴$ry$ y方向半轴 $x-axis-rotation$ 关于x轴旋转角度$large-arc-flag$ 0劣弧 1优弧$sweep-flag$起点到终点 0逆时针弧 1顺时针弧$x,y$终点 m, l, v, h, z, c, s, q, t, a $dx_i dy_i$ 小写是大写的简化, 只需要坐标变化量即可 便捷但可读性不强 每次使用path前, 都需要使用M移动到具体位置 贝塞尔曲线广泛应用于计算机平滑曲线制作, 包括 .ttf 字体设计.三次贝塞尔曲线参数形式: \\mathbf{B}(t)=\\mathbf{P}_{0}(1-t)^{3}+3 \\mathbf{P}_{1} t(1-t)^{2}+3 \\mathbf{P}_{2} t^{2}(1-t)+\\mathbf{P}_{3} t^{3}, t \\in[0,1]贝塞尔曲线一般参数形式: \\mathbf{B}(t)=\\sum_{i=0}^{n}\\left(\\begin{array}{l}n \\\\ i\\end{array}\\right) \\mathbf{P}_{i}(1-t)^{n-i} t^{i}, t \\in[0,1] 以知两点和椭圆长短半轴和旋转角度通常可以画四条弧, A中的参数就是为了确定是哪一条弧. z只能在一个path命令中使用,即一笔画 一些例子我用上面的所有path语法, 乱画一通, 如下1234567891011121314&lt;?xml version=\"1.1\" standalone=\"no\"?&gt;&lt;svg width=\"200px\" height=\"200px\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\"&gt; &lt;path d=\"M10 10 L 20 100\" stroke=\"black\" fill=\"transparent\"/&gt; &lt;path d=\"M20 100 V 5 \" stroke=\"green\" fill=\"transparent\"/&gt; &lt;path d=\"M20 5 H 60 \" stroke=\"orange\" fill=\"transparent\"/&gt; &lt;path d=\"M60 5 C 30 20, 30 60, 65 100 \" stroke=\"purple\" fill=\"transparent\"/&gt; &lt;path d=\"M65 100 S 100 140, 20 160 \" stroke=\"red\" fill=\"transparent\"/&gt; &lt;path d=\"M20 160 Q 70 180, 80 160 \" stroke=\"blue\" fill=\"transparent\"/&gt; &lt;path d=\"M80 160 T 130 170 \" stroke=\"yellow\" fill=\"transparent\"/&gt; &lt;path d=\"M130 170 A 30 60 0 0 0 170 50 \" stroke=\"brown\" fill=\"transparent\"/&gt; &lt;path d=\"M10 10 L170 50 \" stroke=\"pink\" fill=\"transparent\"/&gt; &lt;/svg&gt;结果如下: Fill 和 Stroke 属性fill和stroke分别对应填充颜色和线条颜色. 此外还有很多他们的延申属性. 着色画一个红边蓝底的矩形框**-opacity代表透明度设置, 颜色命名方案支持CSS颜色命名方案, 即颜色名（如red）、rgb值（如rgb(255,0,0)）、十六进制值、rgba值12&lt;rect x=\"10\" y=\"10\" height=\"50\" width=\"50\" stroke=\"rgb(255,0,0)\" fill=\"#0000FF\" fill-opacity=\"0.3\" stroke-opacity=\"0.8\" /&gt; 描边stroke-width 线宽stroke-linecap 描边方式三种: 无描边, 方形描边, 圆角描边123&lt;line x1=\"20\" x2=\"70\" y1=\"80\" y2=\"80\" stroke=\"black\" stroke-width=\"6\" stroke-linecap=\"butt\"/&gt;&lt;line x1=\"20\" x2=\"70\" y1=\"100\" y2=\"100\" stroke=\"rgb(255,255,255)\" stroke-width=\"8\" stroke-linecap=\"square\"/&gt;&lt;line x1=\"20\" x2=\"70\" y1=\"120\" y2=\"120\" stroke=\"#FFFFFF\" stroke-width=\"10\" stroke-linecap=\"round\"/&gt;还有, stroke-linejoin属性控制折线折角风格| 值 | 效果 || :——-: | :—————-: || miter | 尖角无修饰 || round | 圆角, 圆润 || bevel | 斜角,切去尖角 | stroke-dasharray用于画虚线, 接 $n_1,n_2…n_i$, 分别代表 $n_i$px 个填充或空白, 循环着色.1234&lt;path d=\"M 10 75 Q 50 10 100 75 T 190 75\" stroke=\"black\" stroke-linecap=\"round\" stroke-dasharray=\"5,10,5\" fill=\"none\"/&gt;&lt;path d=\"M 10 75 L 190 75\" stroke=\"red\" stroke-linecap=\"round\" stroke-width=\"1\" stroke-dasharray=\"5,5\" fill=\"none\"/&gt;还有一些其他常见的修饰属性, 查阅参考文档. 使用CSS可以像在Html中一样使用CSS, 有些地方需要更换一下属性名字. 但是根据SVG的规范, properties 可以用CSS设置, attributes则不可以. 直接在元素行间设置属性1&lt;rect x=\"10\" height=\"180\" y=\"10\" width=\"180\" style=\"stroke: red; stroke-width: 5; fill: blue;\"/&gt; 设置样式段落利用&lt;style&gt;设置一段样式段落, 在html里这样的&lt;style&gt;一般放在&lt;head&gt;里，在svg里&lt;style&gt;则放在&lt;defs&gt;标签里12345678910&lt;defs&gt; &lt;style type=\"text/css\"&gt;&lt;![CDATA[ #MyRect &#123; stroke: green; stroke-width: 7; fill: yellow; &#125; ]]&gt;&lt;/style&gt;&lt;/defs&gt;&lt;rect x=\"10\" height=\"180\" y=\"10\" width=\"180\" id=\"MyRect\"/&gt; 定义外部样式表要求符合normal XML-stylesheet syntax的规则. 可以在SVG中运用.最好学一点CSS的知识, 获得更好的表现能力. 此外一些CSS可能在SVG中无法正常工作. 渐变渐变是很多很酷的显示效果的基础功能, 一般有线性渐变和径向渐变.我们一般将渐变定义在&lt;defs&gt;中, 并用一个id属性指代它们, 方便复用. 线性渐变 径向渐变 较为复杂且费力, 这会是一个很有帮助的参考, 必要时学习并使用.https://developer.mozilla.org/zh-CN/docs/Web/SVG/Tutorial/Gradients 图案图案可以之前学过的任意图形来实现对画布的填充. 一个天蓝色矩形, 一个边长是前者一半大小的红色矩形, 一个半透明的圆, 组成了最基本的图案单元.123456789101112131415161718192021222324252627282930313233343536&lt;?xml version=\"1.0\" standalone=\"no\"?&gt;&lt;svg width=\"750\" height=\"200\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\"&gt; &lt;defs&gt; &lt;linearGradient id=\"Gradient1\"&gt; &lt;stop offset=\"5%\" stop-color=\"white\"/&gt; &lt;stop offset=\"95%\" stop-color=\"blue\"/&gt; &lt;/linearGradient&gt; &lt;linearGradient id=\"Gradient2\" x1=\"0\" x2=\"0\" y1=\"0\" y2=\"1\"&gt; &lt;stop offset=\"5%\" stop-color=\"red\"/&gt; &lt;stop offset=\"95%\" stop-color=\"orange\"/&gt; &lt;/linearGradient&gt; &lt;pattern id=\"Pattern\" x=\"0\" y=\"0\" width=\".25\" height=\".25\"&gt; &lt;rect x=\"0\" y=\"0\" width=\"50\" height=\"50\" fill=\"skyblue\"/&gt; &lt;rect x=\"0\" y=\"0\" width=\"25\" height=\"25\" fill=\"url(#Gradient2)\"/&gt; &lt;circle cx=\"25\" cy=\"25\" r=\"20\" fill=\"url(#Gradient1)\" fill-opacity=\"0.5\"/&gt; &lt;/pattern&gt; &lt;pattern id=\"Pattern1\" width=\".25\" height=\".25\" patternContentUnits=\"objectBoundingBox\"&gt; &lt;rect x=\"0\" y=\"0\" width=\".25\" height=\".25\" fill=\"skyblue\"/&gt; &lt;rect x=\"0\" y=\"0\" width=\".125\" height=\".125\" fill=\"url(#Gradient2)\"/&gt; &lt;circle cx=\".125\" cy=\".125\" r=\".1\" fill=\"url(#Gradient1)\" fill-opacity=\"0.5\"/&gt; &lt;/pattern&gt; &lt;pattern id=\"Pattern2\" x=\"10\" y=\"10\" width=\"50\" height=\"50\" patternUnits=\"userSpaceOnUse\"&gt; &lt;rect x=\"0\" y=\"0\" width=\"50\" height=\"50\" fill=\"skyblue\"/&gt; &lt;rect x=\"0\" y=\"0\" width=\"25\" height=\"25\" fill=\"url(#Gradient2)\"/&gt; &lt;circle cx=\"25\" cy=\"25\" r=\"20\" fill=\"url(#Gradient1)\" fill-opacity=\"0.5\"/&gt; &lt;/pattern&gt; &lt;/defs&gt; &lt;rect fill=\"url(#Pattern)\" stroke=\"black\" x=\"0\" y=\"0\" width=\"250\" height=\"200\"/&gt; &lt;rect fill=\"url(#Pattern1)\" stroke=\"black\" x=\"250\" y=\"0\" width=\"250\" height=\"200\"/&gt; &lt;rect fill=\"url(#Pattern2)\" stroke=\"black\" x=\"500\" y=\"0\" width=\"250\" height=\"200\"/&gt;&lt;/svg&gt; Pattern注意到width=&quot;.25&quot; height=&quot;.25&quot;, 44填充, *不会拉伸, 不够的地方是空白. Pattern1使用patternContentUnits, 默认值为userSpaceOnUse, 当设置其值为objectBoundingBox, 将不再使用Pattern本身的坐标而是使用画布的坐标系统, 需要计算宽和高的比例 0~1, 可以产生拉伸效果. Pattern2属性patternUnits, 默认值为objectBoundingBox, 当设置其值为userSpaceOnUse, 可以加入x=&quot;10&quot; y=&quot;10&quot;设置Pattern的偏移量, 也可以写成x=&quot;1/30&quot; y=&quot;0.05&quot;. 10/300=1/30 10/200=0.05. 可以产生平移效果. 文字SVG能显示一切字符, 拥有丰富的格式修饰 &lt;text&gt;元素用来放文字, 可以指定位置, 字号, 对齐, 填充, 描边text-anchor有start、middle、end或inherit几种值可选.12345678910&lt;svg version=\"1.1\" baseProfile=\"full\" width=\"600\" height=\"100\" xmlns=\"http://www.w3.org/2000/svg\"&gt; &lt;rect width=\"100%\" height=\"100%\" fill=\"red\" /&gt; &lt;text id=\"example\" x=\"350\" y=\"50\" font-size=\"30\" text-anchor=\"middle\" stroke=\"green\" fill=\"yellow\"&gt;₰汉字⅝English🌊π🦾 &lt;tspan font-weight=\"bold\" fill=\"red\"&gt; bold and red&lt;/tspan&gt; &lt;/text&gt; &lt;path id=\"my_path\" d=\"M 20,20 C 40,40 80,40 100,20\" /&gt; &lt;text&gt; &lt;textPath xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#my_path\"&gt;This text follows a curve.&lt;/textPath&gt; &lt;/text&gt;&lt;/svg&gt; 常见的属性包括font-family、font-style、font-weight、font-variant、font-stretch、font-size、font-size-adjust、kerning、letter-spacing、word-spacing和text-decoration可以被设置为一个SVG属性或者成为一个CSS声明 一些特别的元素 tspan该元素用来标记大块文本的子部分，它必须是一个text元素或别的tspan元素的子元素。它的一些属性可以重新定义文字位置, 旋转文字, 定义文本长度 tref引用已经定义的文本，高效地把它复制到当前位置(貌似没用) textPath利用它的xlink:href属性取得一个任意路径，把字符对齐到路径 基础变形包括平移, 旋转, 斜切, 缩放等基本的图形变换. 平移translate(dx,dy)1&lt;rect x=\"0\" y=\"0\" width=\"10\" height=\"10\" transform=\"translate(30,40)\" /&gt; 旋转rotate(α)按角度计算1&lt;rect x=\"20\" y=\"20\" width=\"20\" height=\"20\" transform=\"rotate(45)\" /&gt; 斜切skewX(α), skewY(θ)角度确定元素斜切到哪里 缩放scale(x%, y%)规定缩放的比例, 通常用小数, y轴的比例可以省略 剪裁和遮罩https://developer.mozilla.org/zh-CN/docs/Web/SVG/Tutorial/Clipping_and_masking 插入图片为了表达对小袁的思念, 在她面前做了这个图,12345678910&lt;!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\" \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\"&gt;&lt;svg version=\"1.1\" standalone=\"no\" width=\"900\" height=\"600\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink= \"http://www.w3.org/1999/xlink\"&gt; &lt;rect width=\"100%\" height=\"100%\" fill=\"purple\" /&gt; &lt;text x=\"450\" y=\"100\" font-size=\"40\" text-anchor=\"middle\" fill=\"white\"&gt;我爱小袁&lt;/text&gt; &lt;image xlink:href=\"https://cdn.jsdelivr.net/gh/18wang/media/xy.jpg\" x=\"250\" y=\"200\" height=\"400\" /&gt;&lt;/svg&gt; 点击这里, 图片可能加载不全 一个xlink:href属性引用了一个将呈现在SVG对象中的.jpg图像, 注意要包含xmlns:xlink= &quot;http://www.w3.org/1999/xlink才行, 否则会出错.还有一些注意点: 如果你没有设置x属性或y属性，它们自动被设置为0。 如果你没有设置height属性或width属性，它们自动被设置为0。 如果width属性或height等于0，将不会呈现这个图像。 图片可以是来自文件或者网页(只要有网全世界都可以看到该图片)","categories":[],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2020-03-22T03:06:34.642Z","updated":"2020-03-19T13:40:05.717Z","comments":true,"path":"2020/03/22/hello-world/","link":"","permalink":"https://github.com/18wang/2020/03/22/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start Create a new post 1$ hexo new \"My New Post\" More info: Writing Run server 1$ hexo server More info: Server Generate static files 1$ hexo generate More info: Generating Deploy to remote sites 1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}